from keras.applications import MobileNet
from __future__ import print_function
import keras
from keras.preprocessing.image import ImageDataGenerator

from keras.models import Sequential
from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D, ZeroPadding2D
from keras.layers.normalization import BatchNormalization
from keras.models import Model

import os
import matplotlib.pyplot as plt
import sklearn
from sklearn.metrics import classification_report, confusion_matrix
import numpy as np

from keras.optimizers import RMSprop, SGD, Adam
from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau

from keras.preprocessing import image
from os import listdir
from os.path import isfile, join
import re
import matplotlib.image as mpimg
import cv2


# MobileNet was designed to work on 224 x 224 pixel input images sizes
img_rows, img_cols = 224, 224 

# Re-loads the MobileNet model without the top or FC layers
model = MobileNet(weights = 'imagenet', include_top = False, input_shape = (img_rows, img_cols, 3))

# Here we freeze the last 4 layers 
# Layers are set to trainable as True by default
for layer in model.layers[:-11]:
    layer.trainable = False
    
    
for layer in model.layers:
    print(layer,layer.trainable)
    
    
for (i,layer) in enumerate(model.layers):
    print(str(i) + " "+ layer.__class__.__name__, layer.trainable)
    

def addTopModelMobileNet(bottom_model, num_classes):
    #"""creates the top or head of the model that will be 
    #placed ontop of the bottom layers"""

    top_model = bottom_model.output
    top_model = GlobalAveragePooling2D()(top_model)
    top_model = Dense(1024,activation='relu')(top_model)
    top_model = Dense(1024,activation='relu')(top_model)
    top_model = Dense(512,activation='relu')(top_model)
    top_model = Dense(num_classes,activation='softmax')(top_model)
    return top_model

num_classes = 151

FC_Head = addTopModelMobileNet(model, num_classes)

model = Model(inputs = model.input, outputs = FC_Head)

print(model.summary())


path='/home/kiran/Documents/ear recog/UERC Competition Package 2019/Dataset/Train Dataset'
def dataset(mode):
    
    total_images = []
    label=[]
    mode_path = os.path.join(path,mode)
    subjects = os.listdir(mode_path)

    for subject in subjects:
        image_path  = os.path.join(mode_path,subject)
        images = os.listdir(image_path)
        for image in images:
            if(image.endswith(".png")):
                file = os.path.join(image_path,image)
                total_images.append(cv2.resize(cv2.imread(file),(224,224)))
                label.append(int(subject))
    total_images = np.array(total_images)
    label = np.array(label)
    return total_images , label

train,label = dataset('output')


def split_data(data,label,valid_len):
    valid_len = int(valid_len*len(data)/100)
    return (data[0:len(data)-valid_len],label[0:len(data)-valid_len],
            data[len(data)-valid_len:len(data)],label[len(data)-valid_len:len(data)])
x_train,y_train,x_valid,y_valid = split_data(train,label,30)



y_train = keras.utils.to_categorical(y_train, 151)
y_valid= keras.utils.to_categorical(y_valid, 151)



checkpoint = ModelCheckpoint("trained_model/monkey_breed_mobileNet_adam1.h5", monitor="val_loss", mode="min", 
                             save_best_only = True, verbose=1)

model.compile(loss=keras.losses.categorical_crossentropy,
              optimizer='Adam',
              metrics=['accuracy'])
              
              
history=model.fit(x_train, y_train,
          batch_size=1,
          epochs=20,
          verbose=1,
          validation_data=(x_valid, y_valid))
#m1 = load_model('trained_model/monkey_breed_mobileNet_adam1.h5')

fig, ax = plt.subplots(2,1)
ax[0].plot(history.history['loss'], color='b', label="Training loss")
ax[0].plot(history.history['val_loss'], color='r', label="validation loss",axes =ax[0])
legend = ax[0].legend(loc='best', shadow=True)

ax[1].plot(history.history['acc'], color='b', label="Training accuracy")
ax[1].plot(history.history['val_acc'], color='r',label="Validation accuracy")
legend = ax[1].legend(loc='best', shadow=True)


predictions_valid = model.predict(X_valid, batch_size=batch_size, verbose=1)

score = log_loss(Y_valid, predictions_valid)

print(score)
